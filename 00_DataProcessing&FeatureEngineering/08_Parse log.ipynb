{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 7 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-26181c0bd15a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m ]\n\u001b[0;32m     76\u001b[0m     \u001b[0mua_pd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ua_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspiders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mua_pd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ip_add'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'requet_time'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'request_info'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'status'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'bytes_info'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'referral'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ua'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0moutput_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ua_result_{0}.xlsx'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y%m%d%H%M%S'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mua_pd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5191\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5192\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5193\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5194\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    691\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    181\u001b[0m             raise ValueError(\n\u001b[0;32m    182\u001b[0m                 \u001b[1;34m\"Length mismatch: Expected axis has {old} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[1;34m\"values have {new} elements\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mold_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             )\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 7 elements"
     ]
    }
   ],
   "source": [
    "import gzip    # 读取gz压缩包中的文件\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 判断日志数据中是否为爬虫日志\n",
    "def is_spider(log_record, spiders):\n",
    "    detect_result = [True if log_record.find(spider) == -1 else False for spider in spiders]\n",
    "    is_exist = True if all(detect_result) else False\n",
    "    return is_exist\n",
    "\n",
    "# 判断是否为UA记录\n",
    "def is_ua_record(log_record):\n",
    "    is_ua = True if log_record.find('GET / ua.gif?') != -1 else False\n",
    "    return is_ua\n",
    "\n",
    "# 解析日志文件中的每条日志数据\n",
    "def split_ua_data(line):\n",
    "    # 定义不同日志分割的正则表达式\n",
    "    ip_pat = '[\\d.]*'    # 定义IP规则，例如203.208.60.230\n",
    "    time_pat = '\\[[^\\[\\]]*\\]'   # 定义时间规则，例如[02/Mar/2016:14:00:23 +0800]\n",
    "    request_pat = '\\\"[^\\\"]*\\\"'    # 定义请求规则\n",
    "    status_pat = '\\d+'    # 定义返回的状态码规则，例如200\n",
    "    bytes_pat = '\\d+'    # 返回的字节数，例如326\n",
    "    refer_pat = '\\\"[^\\\"]*\\\"'    # 定义refer规则\n",
    "    user_agent_pat = '\\\"[^\\\"]*\\\"'    # 定义user agnet规则\n",
    "    # 原理：主要通过空格和-来区分各不同项目，各项目内部写各自的匹配表达式\n",
    "    re_pattern = re.compile('(%s)\\ -\\ -\\ (%s)\\ (%s)\\ (%s)\\ (%s)\\ (%s)\\ (%s)' % (\n",
    "        ip_pat, time_pat, request_pat, status_pat, bytes_pat, refer_pat, user_agent_pat),\n",
    "                                re.VERBOSE)    # 完整表达式模式\n",
    "    matchs = re_pattern.match(line)    # 匹配\n",
    "    if matchs != None:    # 如果不为空\n",
    "        allGroups = matchs.groups()    # 获得所有匹配的列表\n",
    "        return allGroups[0],allGroups[1],allGroups[2],allGroups[3],allGroups[4],allGroups[5],allGroups[6]\n",
    "    else:   # 否则返回空\n",
    "        return '','','','','','',''\n",
    "\n",
    "# 读取日志数据\n",
    "def get_ua_data(file,spiders):\n",
    "    ua_data = []\n",
    "    with gzip.open(file, 'rt') as fn:    # 打开要读取的日志文件对象\n",
    "        content = fn.readlines()    # 以列表形式读取日志数据\n",
    "    for single_log in content:    # 循环判断每天记录\n",
    "        rule1 = is_spider(single_log,spiders)\n",
    "        rule2 = is_ua_record(single_log)\n",
    "        if rule1 and rule2:    # 如果同时符合2条规则，则执行\n",
    "            ua_data.append(split_ua_data(single_log))\n",
    "    ua_pd = pd.DataFrame(ua_data)\n",
    "    return ua_pd\n",
    "\n",
    "#主程序\n",
    "if __name__ == '__main__':\n",
    "    file = '..\\dataset\\dataivy.cn-Feb-2018.gz'  # 定义原始日志的文件名\n",
    "    spiders = [\n",
    "    'AhrefsBot',\n",
    "    'archive.org_bot',\n",
    "    'baiduspider',\n",
    "    'Baiduspider',\n",
    "    'bingbot',\n",
    "    'DeuSu',\n",
    "    'DotBot',\n",
    "    'Googlebot',\n",
    "    'iaskspider',\n",
    "    'MJ12bot',\n",
    "    'msnbot',\n",
    "    'Slurp',\n",
    "    'Sogou web spider',\n",
    "    'Sogou Push Spider',\n",
    "    'SputnikBot',\n",
    "    'Yahoo! Slurp China',\n",
    "    'Yahoo! Slurp',\n",
    "    'YisouSpider',\n",
    "    'YodaoBot',\n",
    "    'bot.html'\n",
    "]\n",
    "    ua_pd = get_ua_data(file,spiders)\n",
    "    ua_pd.columns = ['ip_add','requet_time','request_info','status','bytes_info','referral','ua']\n",
    "    output_file = 'ua_result_{0}.xlsx'.format(time.strftime('%Y%m%d%H%M%S',time.localtime(time.time())))\n",
    "    ua_pd.to_excel(output_file, index=False)\n",
    "    print('excel file {0} generated!'.format(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
