## 模型评估与选择
---

### 1、过拟合与欠拟合

**经验误差：**
指模型学习训练样本后，输出的实际预测值域样本的真实值之间的差异

**过拟合：**
指模型对于训练数据拟合呈现过当的情况(将训练样本自身的一些特点也当做所有潜在样本都会具有的一般性质)，反映在评估指标上就是模型在训练集上表现很好，但在测试集和新数据集上表现较差，**即模型的泛化性能下降**。

**欠拟合：**
通常由于学习能力低下造成的，模型在训练和预测时表现都不好的情况。欠拟合比较容易克服，例如在决策树学习中扩展分支，神经网络学习中增加训练轮数等。

**降低过拟合和欠拟合的方法**
- **降低过拟合的方法**
1. 从数据入手，获取更多的训练数据。使用更多的训练数据时解决过拟合的最有效的方法，因为更多的样本能够让模型学习到更多更有效的手段，减少噪声的影响。当然，直接增加实验数据一般是很困难的，但可以通过一定的规则来扩充训练数据。
2. 降低模型复杂度。在数据较少时，模型过于复杂是产生过拟合的主要因素，适度降低模型复杂度可以避免模型拟合过多的采样噪声。
3. 正则化方法。给模型的参数加上一定的正则约束，比如将权值的大小加入到损失函数中。以L2正则化为例，如下公式，这样在优化原来的目标函数C0的同时，也能避免权值过大带来的过拟合风险。
```math
C = C_0 + \frac{\lambda}{2n} \sum_i{w_i^2}
```
4. 集成学习方法。集成学习是把多个模型集成在一起，来降低单一模型的过拟合风险，如Bagging方法。


- **降低欠拟合的方法**
1. 添加新特征；当特征不足或现有特征与样本标签的相关性不强时，模型容易出现欠拟合。通过挖掘“上下文特征”，“ID类特征”，“组合特征”等新的特征，来改善模型的效果。现在常用的方法有：因子分解机、梯度提升决策树等可以成为丰富特征的方法。
2. 增加模型复杂度；简单模型的学习能力较差，通过增加模型的复杂度可以使模型具有更强的拟合能力。如在线性模型中增加高次项，在神经网络模型中增加网络层数或神经元个数等。
3. 减少正则化系数；正则化是用来防止过拟合的，但当模型出现欠拟合现象时，则需要有针对性地减小正则化系数。
---

### 2、模型评估方法
在机器学习中，我们通常会把样本分为训练集和测试集，训练集用于训练模型，测试集用于评估模型。在样本划分和模型验证的过程中，存在着不同的抽样方法和验证方法，需要我们根据需要进行采用。常见的方法有留出法、交叉验证法、自助法等。

#### 2.1 留出法(Hold-out)
留出法是最简单也是最直接的验证方法，它将原始样本数据随机划分成训练集和测试集(互斥的)两部分。通常会按照70%-30%的比例划分，70%的样本用于模型训练，30%的样本用于模型验证，包括ROC曲线的绘制、计算精确率和召回率等指标。

**留出法需注意的点：**
- 样本的划分要尽可能的保持数据分布的一致性，避免因数据划分过程中引入额外的偏差而对最终结果产生影响
- 即便在给定训练/测试集的样本比例后，仍然存在多种划分方式对初始数据集D进行分割。一般要采用若干次随机划分，重复进行实验评估后取平均值作为留出法的评估结果。
- 由于留出法的缺点比较明显，即在验证集上计算出来的最后评估指标与原始分组有很大关系。为了消除随机性，引入了“交叉验证”的思想。

#### 2.2 交叉验证法
**k-fold交叉验证：** 将全部样本划分为k个大小相等的子集，每次将k-1个子集作为训练集，余下的子集作为测试集，这样就可以得到k个测试结果，最后返回k个结果的均值用于模型的评估。在实际实验中k常取10。

**留一法**
每次留下1个样本作为验证集，其余的作为测试集。因为留一法的训练集相比初始数据集仅少一个样本，因此在实际实验中结果往往被认为比较准确，但缺点很明显，就是在数据集较大时，时间上的开销太大。

#### 2.3 自助法
**背景：**
留出法与交叉验证都是基于划分训练集与测试集的基础上进行的模型评估，由于实际评估模型所使用的的训练集比初始数据集小，会引入一些因训练样本规模不同而导致的估计偏差。例如当样本规模比较小的时候，将样本再进行划分会导致训练集进一步减小，从而会影响模型训练效果。

维持训练集样本规模的验证方法--自助法就可以很好的解决以上问题。

**自助法**是基于自主采样法的检验方法。对于总数为n的样本集合，进行n次有放回的随机抽样，得到大小为n的训练集。n次采样过程中，有点样本会被重复采样，有的则没有被抽出过，将没有被抽出过的样本作为验证集，进行模型验证。

**自助法需注意的点：** 当样本数据集较小，难以划分训练/测试集时很有用，但自助法产生的数据集会改变初始数据集的分布，这会引入估计偏差，因此在初始数据充足时，留出法和交叉验证更常用一些。

**自助法采样过程中，会有多少数据从未被选择过？**
初始样本量为n，进行n次自助抽样，一个样本在一次抽样过程中未被抽中的概率为：
```math
(1 -\frac{1}{n})
```
n次抽样均为被抽中的概率为：
```math
(1 -\frac{1}{n})^n
```
当n趋于无穷大时，概率为：
```math
\lim\limits_{{n \rightarrow \infty}} \ (1 -\frac {1} {n})^n
=\lim\limits_{{n \rightarrow \infty}} \frac{1}{(1 +\frac{1}{n-1})^n}

=\lim\limits_{{n \rightarrow \infty}} \frac{1}{(1 +\frac{1}{n-1})^{n-1}}\  \ast \ \lim\limits_{{n \rightarrow \infty}} \frac{1}{(1 +\frac{1}{n-1})}

= \frac{1}{e} \approx {0.368}
```
根据重要极限
```math
\lim\limits_{{n \rightarrow \infty}}{(1 +\frac{1}{n})^n} = e
```
故可以看出当样本数较大时，大约有36.8%的样本从未被选择过，可以作为验证集。

#### 2.4 参数调优
一般情况下学习算法都会有参数需要设定，参数配置不同，学习模型的性能往往会产生显著差别；因此在进行模型评估与选择时，除了要对使用学习算法进行选择，还需要对算法参数进行设定。

**超参数搜索算法一般包含的要素有：**
- 目标函数：即算法需要最大化/最小化的目标
- 搜索范围：一般通过上限和下限来确定
- 算法的其他参数：如搜索步长

**超参数调优的方法：**
- 网格搜索：
~~~~
1. 网格搜索基本是最简单、应用最广泛的超参数搜索算法，通过搜索范围内的所有点来确定最优值。
2. 如果采用较大的搜索范围以及较小的步长，网格搜索有极大概率找到全局最优值。缺点是比较消耗计算资源与实践，特别是需调优的超参数比较多时。
3. 网格搜索的步骤一般如下：
- 先使用较广的搜索范围和较大的步长，来寻找全局最优值可能的位置；
- 然后逐渐缩小搜索范围和步长来寻找更精确的最优值；
4. 采用3中的步骤可以降低所需的时间和计算量，但由于目标函数一般是非凸的，所以很可能会错过全局最优值。
~~~~
- 随机搜索
~~~~
1. 随机搜索的思想和网格搜索比较相似，只是不再测试上界和下界之间的所有值，而是在搜索范围中随机选取样本点；
2. 随机搜索的理论依据是：如果样本点集足够大，那么通过随机采样也能大概率找到全局最优值或其近似值；
3. 随机搜索一般会比网格搜索要快一些，单核网格搜索一样，它的结果也是没法保证的
~~~~
- 贝叶斯优化算法
~~~~
1. 贝叶斯优化算法在寻找最优值超参数时，与网格搜索和随机搜索完全不同，前两者在测试一个新点时，会忽略前一个点的信息，而贝叶斯优化算法会充分利用之前的信息；
2. 贝叶斯优化算法通过对目标函数形状进行学习，找到使目标函数向全局最优值提升的参数；
3. 具体步骤如下：
  - 首先根据先验分布，假设一个搜集函数
  - 然后每一次使用新的采样点来测试目标函数时，利用这个信息来更新目标函数的先验分布
  - 最后算法测试由后验分布给出的全局最值最可能出现的位置的点
4. 该方法有一个缺点：就是一旦找到一个局部最优值，它会在该区域不断采样，容易陷入局部最优值；为弥补该缺陷，贝叶斯优化算法会在探索和利用之间找到一个平衡点，探索是在还未取样的区域获取采样点，利用是根据后验分布在最可能出现全局最值的区域进行采样。
~~~~

**参考教程：**
> [1] 周志华 《机器学习》
> 
> [2] 百面机器学习--算法工程师带你去面试
