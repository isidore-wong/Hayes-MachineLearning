{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18790469, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "path = os.getcwd()\n",
    "train_sample_file = os.path.join(path, './data/sample_submission.csv')\n",
    "\n",
    "data_train = pd.read_csv(train_sample_file)\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def Main():\n",
    "    source_dir = '/data/u_lx_data/zhangqm/sh/yanjie/liuxuesheng/jz_yuanshi_list0206.txt'\n",
    "    target_dir = '/data/u_lx_data/zhangqm/sh/yanjie/liuxuesheng/split/'\n",
    "\n",
    "    # 计数器\n",
    "    flag = 0\n",
    "\n",
    "    # 文件名\n",
    "    name = 1\n",
    "\n",
    "    # 存放数据\n",
    "    dataList = []\n",
    "    print(\"开始分割文件\")\n",
    "    print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    with open(source_dir,'r') as f_source:\n",
    "        for line in f_source:\n",
    "            flag += 1\n",
    "            dataList.append(line)\n",
    "            if flag == 10000000:\n",
    "                with open(target_dir+\"jz_yuanshi_list_\"+str(name)+\".csv\",'w+') as f_target:\n",
    "                    for data in dataList:\n",
    "                        f_target.write(data)\n",
    "                name += 1\n",
    "                flag = 0\n",
    "                dataList = []\n",
    "\n",
    "    # 处理最后一批行数少于200万行的\n",
    "    with open(target_dir+\"jz_yuanshi_list_\"+str(name)+\".txt\",'w+') as f_target:\n",
    "        for data in dataList:\n",
    "            f_target.write(data)\n",
    "        print(\"完成。。。。。\")\n",
    "\n",
    "    print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.jianshu.com/p/f935673ef524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作用：根据需要拆分的文件数，拆分文件\n",
    "# 备注：可以拆分csv格式文件和txt格式文件，返回的数据均是没有表头\n",
    "import os\n",
    "import pandas\n",
    "\n",
    "def file_split(filename, file_num, header=True):\n",
    "    #根据是否有表头执行不同程序，默认是否表头的\n",
    "    if header:\n",
    "        # 获得每个文件需要有的行数\n",
    "        chunksize = 1000000   #先初始化的chunksize是100W\n",
    "        data1 = pd.read_table(filename, chunksize = chunksize, sep=',', encoding='gbk') \n",
    "        num = 0\n",
    "        for chunk in data1:\n",
    "            num += len(chunk)\n",
    "        chunksize = round(num / file_num + 1)\n",
    "\n",
    "        # 需要存的file\n",
    "        head, tail = os.path.splitext(filename)\n",
    "        data2 = pd.read_table(filename, chunksize = chunksize, sep=',', encoding='gbk')\n",
    "        i = 0 #定文件名\n",
    "        for chunk in data2:\n",
    "            chunk.to_csv('{0}_{1}{2}'.format(head, i, tail),header=None,index=False)\n",
    "            print('保存第{0}个数据'.format(i))\n",
    "            i += 1\n",
    "    else:\n",
    "        # 获得每个文件需要有的行数\n",
    "        chunksize = 1000000   #先初始化的chunksize是100W\n",
    "        data1 = pd.read_table(filename, chunksize = chunksize ,header=None, sep=',') \n",
    "        num = 0\n",
    "        for chunk in data1:\n",
    "            num += len(chunk)\n",
    "        chunksize = round(num / file_num + 1)\n",
    "\n",
    "        # 需要存的file\n",
    "        head, tail = os.path.splitext(filename)\n",
    "        data2 = pd.read_table(filename, chunksize = chunksize ,header=None, sep=',')\n",
    "        i = 0 #定文件名\n",
    "        for chunk in data2:\n",
    "            chunk.to_csv('{0}_{1}{2}'.format(head, i, tail),header=None,index=False)\n",
    "            print('保存第{0}个数据'.format(i))\n",
    "            i += 1\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    filename = 'D:\\\\bigdata.csv'\n",
    "    file_split(filename, 5, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
