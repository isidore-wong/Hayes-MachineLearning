{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对数据样本进行特征转换的降维\n",
    "常见的降维包括：独立成分分析ICA、主成分分析PCA、因子分析FA、线性判别分析LDA、局部线性嵌入LLE、核主成分分析Kernel PCA等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import feature_selection\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import PolynomialFeatures as plf\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBDT\n",
    "from sklearn import datasets\n",
    "from gplearn.genetic import SymbolicTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.886230</td>\n",
       "      <td>1.317859</td>\n",
       "      <td>-0.164806</td>\n",
       "      <td>0.565369</td>\n",
       "      <td>-1.119345</td>\n",
       "      <td>-0.532190</td>\n",
       "      <td>-0.684310</td>\n",
       "      <td>1.241498</td>\n",
       "      <td>1.005792</td>\n",
       "      <td>0.454850</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.450163</td>\n",
       "      <td>0.670809</td>\n",
       "      <td>-1.165714</td>\n",
       "      <td>1.166539</td>\n",
       "      <td>3.276056</td>\n",
       "      <td>-0.872706</td>\n",
       "      <td>-0.310676</td>\n",
       "      <td>-0.949465</td>\n",
       "      <td>-0.331942</td>\n",
       "      <td>-2.943994</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.481587</td>\n",
       "      <td>0.335247</td>\n",
       "      <td>0.722109</td>\n",
       "      <td>-2.017945</td>\n",
       "      <td>-0.425526</td>\n",
       "      <td>-0.980505</td>\n",
       "      <td>1.570869</td>\n",
       "      <td>1.469196</td>\n",
       "      <td>-1.683878</td>\n",
       "      <td>1.449332</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.701114</td>\n",
       "      <td>-0.528190</td>\n",
       "      <td>0.056773</td>\n",
       "      <td>1.143343</td>\n",
       "      <td>2.916560</td>\n",
       "      <td>0.245130</td>\n",
       "      <td>-0.362534</td>\n",
       "      <td>1.391917</td>\n",
       "      <td>-0.697423</td>\n",
       "      <td>-2.680853</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.715570</td>\n",
       "      <td>1.138827</td>\n",
       "      <td>-0.387145</td>\n",
       "      <td>0.506031</td>\n",
       "      <td>-1.916972</td>\n",
       "      <td>-1.217661</td>\n",
       "      <td>-0.792914</td>\n",
       "      <td>-0.677494</td>\n",
       "      <td>0.550318</td>\n",
       "      <td>1.043190</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>0.953560</td>\n",
       "      <td>1.000924</td>\n",
       "      <td>-1.826659</td>\n",
       "      <td>-0.938643</td>\n",
       "      <td>-0.063160</td>\n",
       "      <td>0.531305</td>\n",
       "      <td>0.757259</td>\n",
       "      <td>1.248813</td>\n",
       "      <td>-1.648303</td>\n",
       "      <td>0.580475</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>-0.309807</td>\n",
       "      <td>-1.691897</td>\n",
       "      <td>-1.713937</td>\n",
       "      <td>-2.325080</td>\n",
       "      <td>0.276768</td>\n",
       "      <td>-1.311895</td>\n",
       "      <td>1.961194</td>\n",
       "      <td>1.808892</td>\n",
       "      <td>-0.095440</td>\n",
       "      <td>1.136750</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>0.361014</td>\n",
       "      <td>-1.103830</td>\n",
       "      <td>1.265656</td>\n",
       "      <td>-0.525260</td>\n",
       "      <td>2.074481</td>\n",
       "      <td>-0.425352</td>\n",
       "      <td>0.839737</td>\n",
       "      <td>0.964460</td>\n",
       "      <td>2.617705</td>\n",
       "      <td>-1.141681</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>0.886951</td>\n",
       "      <td>0.758980</td>\n",
       "      <td>-1.161209</td>\n",
       "      <td>2.014530</td>\n",
       "      <td>0.532170</td>\n",
       "      <td>1.096608</td>\n",
       "      <td>-1.547043</td>\n",
       "      <td>1.115084</td>\n",
       "      <td>-1.577916</td>\n",
       "      <td>-1.521508</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>0.154441</td>\n",
       "      <td>-0.275286</td>\n",
       "      <td>0.770457</td>\n",
       "      <td>-1.062072</td>\n",
       "      <td>-0.507175</td>\n",
       "      <td>-1.252424</td>\n",
       "      <td>0.770930</td>\n",
       "      <td>0.031578</td>\n",
       "      <td>-0.547570</td>\n",
       "      <td>0.959663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    1.886230  1.317859 -0.164806  0.565369 -1.119345 -0.532190 -0.684310   \n",
       "1    0.450163  0.670809 -1.165714  1.166539  3.276056 -0.872706 -0.310676   \n",
       "2    0.481587  0.335247  0.722109 -2.017945 -0.425526 -0.980505  1.570869   \n",
       "3   -0.701114 -0.528190  0.056773  1.143343  2.916560  0.245130 -0.362534   \n",
       "4    0.715570  1.138827 -0.387145  0.506031 -1.916972 -1.217661 -0.792914   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.953560  1.000924 -1.826659 -0.938643 -0.063160  0.531305  0.757259   \n",
       "996 -0.309807 -1.691897 -1.713937 -2.325080  0.276768 -1.311895  1.961194   \n",
       "997  0.361014 -1.103830  1.265656 -0.525260  2.074481 -0.425352  0.839737   \n",
       "998  0.886951  0.758980 -1.161209  2.014530  0.532170  1.096608 -1.547043   \n",
       "999  0.154441 -0.275286  0.770457 -1.062072 -0.507175 -1.252424  0.770930   \n",
       "\n",
       "            7         8         9   10  \n",
       "0    1.241498  1.005792  0.454850  0.0  \n",
       "1   -0.949465 -0.331942 -2.943994  1.0  \n",
       "2    1.469196 -1.683878  1.449332  1.0  \n",
       "3    1.391917 -0.697423 -2.680853  1.0  \n",
       "4   -0.677494  0.550318  1.043190  0.0  \n",
       "..        ...       ...       ...  ...  \n",
       "995  1.248813 -1.648303  0.580475  1.0  \n",
       "996  1.808892 -0.095440  1.136750  1.0  \n",
       "997  0.964460  2.617705 -1.141681  1.0  \n",
       "998  1.115084 -1.577916 -1.521508  0.0  \n",
       "999  0.031578 -0.547570  0.959663  0.0  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt('..\\dataset\\data1.txt')        # 使用numpy读取数据\n",
    "data_re = pd.DataFrame(data)                     # 将数据转换为DataFrame\n",
    "x, y = data_re.iloc[:, :-1], data_re.iloc[:, -1] # 分割数据，得到输入变量x和输出变量y\n",
    "data_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用sklea的feature_selection做特征选择，以下将尝试多种方法\n",
    "# 采用SelectPercentile选择特征，选取样本总体30%的特征，然后做训练与数据转换\n",
    "selector_1 = feature_selection.SelectPercentile(percentile=30)\n",
    "sel_features1 = selector_1.fit_transform(x, y)\n",
    "# print(sel_features1.shape)\n",
    "# sel_features1[:5]    # 将1000x10的数据集转换为1000x3的数据集，保留其中的3个特征\n",
    "\n",
    "# 采用VarianceThreshold选择特征\n",
    "selector_2 = feature_selection.VarianceThreshold(1)    # 设置阈值1，将方差高于1的特征保留下来\n",
    "sel_features2 = selector_2.fit_transform(x)    \n",
    "# print(sel_features2.shape)    # 原始特征中有7个特征符合条件\n",
    "# sel_features2[:5]\n",
    "\n",
    "# 采用RFE选择特征\n",
    "model_svc = SVC(kernel='linear')    # 指定模型分类器，选择SVC，设置线性内核\n",
    "selector_3 = feature_selection.RFE(model_svc)\n",
    "sel_features3 = selector_3.fit_transform(x, y)\n",
    "# print(sel_features3.shape)    # 原始特征中有5个特征符合条件\n",
    "# sel_features3[:5]\n",
    "\n",
    "# 采用SelectFromModel选择特征\n",
    "model_tree = DecisionTreeClassifier(random_state=0)    # 建立分类决策树模型对象\n",
    "selector_4 = feature_selection.SelectFromModel(model_tree)    # 由于不确定特征重要性的分布，此处不设置特征重要性过滤阈值\n",
    "sel_features4 = selector_4.fit_transform(x, y)\n",
    "# print(sel_features4.shape)    # 原始特征中有3个特征符合条件\n",
    "# sel_features4[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LDA转换后特征数量小于等于目标变量Label唯一值的个数**\n",
    "\n",
    "假设原始数据中的目标变量y的唯一值数量有n个，那么LDA转换后可指定的特征个数最多为n-1. 例如set(y)可以看到y的唯一值域只有2个，故LDA的成分最多只能有1个.那么其成分的解释方差比例就是100%，若是多个成分，会展现每个成分的解释方差比例，其和为1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0, 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# 采用LDA进行维度转换\n",
    "model_lda = LDA()    # 建立LDA模型对象\n",
    "model_lda.fit(x, y)\n",
    "convert_features = model_lda.transform(x)\n",
    "# print(convert_features.shape)    # LDA转换后只有1个特征，该特征不是原有特征，而是转换后的新特征\n",
    "# print(model_lda.explained_variance_ratio_)    # 获得各成分解释方差占比\n",
    "# convert_features[:5]\n",
    "print(set(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GBDT的组合特征是如何产生的**\n",
    "\n",
    "GBDT是由大量tree(默认是CART)的集成，假设在GBDT的参数中设置了小树的个数为3(n_estimators=3)，深度为2(max_depth=2)，在GBDT模型训练之后，\n",
    "就会得到一个基本的GBDT模型；参数n_estimators可自行设置其值，最终特征数量等于n_estimators的树的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.,  4.,  4.,  3.,  5.,  5.,  5.,  4.,  4.,  7.,  7.,  7.,  4.,\n",
       "        7.,  7.,  4.,  7.,  6., 13., 13., 13., 13.,  7., 13., 13.,  7.,\n",
       "       13.,  7., 14.,  7., 12.,  6., 13.,  7., 11.,  3., 14.,  4., 13.,\n",
       "       14.,  4., 11., 13.,  8., 12., 14.,  4., 14.,  3.,  8., 14.,  4.,\n",
       "        6., 12., 10.,  8.,  3., 13., 14.,  9., 10., 10.,  7., 11., 11.,\n",
       "        4., 10., 10., 11.,  3.,  3.,  7.,  9., 10., 14., 13., 11.,  4.,\n",
       "        6., 11., 11.,  6., 14., 14., 10.,  4., 11., 11.,  6., 14.,  6.,\n",
       "       14., 13.,  8., 10., 12., 13.,  4., 11., 14.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 采用sklearn的GBDT方法组合特征\n",
    "model_gbdt = GBDT()\n",
    "model_gbdt.fit(x, y)\n",
    "conbine_features = model_gbdt.apply(x)[:, :, 0]    # 对原始数据做特征提取\n",
    "# GBDT提取特征后的索引节点的形状，新的组合特征是100，已经根据最佳分裂节点做离散化处理，后续可以接其他模型做处理\n",
    "print(conbine_features.shape)    \n",
    "conbine_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PolynomialFeatures(多项式特征组合)方法组合特征**\n",
    "\n",
    "多项式可以完美的拟合出训练集的数据特征，可以通过设置degree的值来指定多项式的项数，但过高的项数可能会造成过拟合，过低的项数可能会导致欠拟合，所以确定最佳的degree值是重点和难点，在二维空间下，一般通过散点图观察数据的分布规律，在高维下。这几乎是不可能的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 66)\n"
     ]
    }
   ],
   "source": [
    "# 采用sklearn的PolynomialFeatures方法组合特征\n",
    "model_plf = plf(2)    # 多项式的项数为2\n",
    "plf_features = model_plf.fit_transform(x, y)\n",
    "print(plf_features.shape)\n",
    "# plf_features[0]\n",
    "# plf_features[:, 0]\n",
    "# plf_features[:, 1:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用gplearn的genetic方法组合特征\n",
    "**遗传算法gplearn主要包含两个处理技术**\n",
    "- SymbolicRegressor(符号回归)，旨在识别最能描述关系的基础数学表达式，它首先建立一个简单随机公式的数量来表示已知自变量与其因变量目标之间的关系，以预测新数据\n",
    "- SymbolicTransformer(符号转换器)是已知监督式的特征处理技术，首先建立一组简单的随机公式来表示关系，然后通过从群体中选择最合适的个体进行遗传操作，最终找出最适合彼此、相关性最小的个体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.2132401 ,  0.83252613, -1.84617541,  0.11456174,  0.48038727])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 采用gplearn的genetic方法组合特征\n",
    "raw_data = datasets.load_boston()\n",
    "x, y = raw_data.data, raw_data.target\n",
    "print(x.shape)    # 数据包含506条记录，13个特征\n",
    "x[0]\n",
    "\n",
    "# 使用SymbolicTransformer方法进行组合，组合后的特征为5个，迭代次数为18\n",
    "model_symbolic = SymbolicTransformer(n_components=5, generations=18,\n",
    "                                     function_set=(\n",
    "                                         'add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg',\n",
    "                                         'inv','max', 'min'),\n",
    "                                     max_samples=0.9, metric='pearson',\n",
    "                                     random_state=0, n_jobs=2)\n",
    "model_symbolic.fit(x, y)\n",
    "symbolic_features = model_symbolic.transform(x)\n",
    "print(symbolic_features.shape)\n",
    "symbolic_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inv(sqrt(inv(sqrt(log(sqrt(inv(mul(X10, X12)))))))),\n",
      " sqrt(inv(sqrt(sqrt(log(mul(X10, X12)))))),\n",
      " inv(log(inv(sqrt(sqrt(sqrt(mul(X10, X12))))))),\n",
      " inv(sqrt(mul(X10, X12))),\n",
      " inv(sqrt(log(mul(X10, X12))))]\n"
     ]
    }
   ],
   "source": [
    "print(model_symbolic)    # 最后生成的5个特征主要是基于第11和13个原始特征，做复杂的公式组合生成的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
